{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P5 : Pipline for Vehicle Detection and Tracking\n",
    "\n",
    "This is the project report for the 5th and final Project for Term-1. Here, I will be going through each of the project rubric points as seprate sections and include explanation with example images to better represent a state of the code pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# importing all the libraries that will be required for this project\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from all_methods import *\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Prep for the pipeline**\n",
    "\n",
    "Loading images in a list and creating a subset of first 3 images to test parameters and methods that is going to be used later in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8792 8968\n"
     ]
    }
   ],
   "source": [
    "# Reading vehicle and non-vehicle images and gettig a sense of the data\n",
    "all_cars = glob.glob('training_samples/vehicles/*/*.png')\n",
    "all_non_cars = glob.glob('training_samples/non-vehicles/*/*.png')\n",
    "print(len(all_cars), len(all_non_cars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotThreeImagesInRow(image1, image2, image3, title1='image1', title2='image2', title3='image3'):\n",
    "    plt.clf() # clear any previous saved data\n",
    "    \n",
    "    # creating layout to place three image sided-by-side with their respective title\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(image1, cmap='gray')\n",
    "    ax1.set_title(title1, fontsize=50)\n",
    "    ax2.imshow(image2, cmap='gray')\n",
    "    ax2.set_title(title2, fontsize=50)\n",
    "    ax3.imshow(image3, cmap='gray')\n",
    "    ax3.set_title(title3, fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    plt.show()\n",
    "    \n",
    "def plotTwoImageInRow(image1, image2, title1='image1', title2='image2'):\n",
    "    plt.clf()\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(image1, cmap='gray')\n",
    "    ax1.set_title(title1, fontsize=50)\n",
    "    ax2.imshow(image2, cmap='gray')\n",
    "    ax2.set_title(title2, fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    plt.show()\n",
    "    \n",
    "#def plotFeaturesHistorgram():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Histogram of Oriented Gradients (HOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.a : Explain how (and identify where in your code) you extracted HOG features from the training images. Explain how you settled on your final choice of HOG parameters.**\n",
    "\n",
    "Following cells describe the method that extracts the HOG feature using the **hog()** method. The following values are set after experimenting with few values. I have chosen these values based on how closely they resemble the features in the original image. \n",
    "\n",
    "The first set of parameters captures the image features but at a top level. The second set of features captures the details in the image more granually. I will be experimenting with the classifier to see which of the two or something in between produces more accurate result keeping time delays less.\n",
    "\n",
    "Final values for the parameter for the hog values can only be set after seeing how it made the classifier perform though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**1.b : Describe how (and identify where in your code) you trained a classifier using your selected HOG features (and color features if you used them)**\n",
    "\n",
    "In the following cells I will be writing the classifier and again testing them with different features combinations to increase the performance of the classifier.\n",
    "\n",
    "I have used the SVM classifier. Following are the steps that goes into building and training the classifier:\n",
    "\n",
    "1. **Extracting features : **I have used a combination of spatial, color histogram and HOG features for this classification. When tested for each of the features individually, I got 0.97 accuracy with only spatial features, 1.0 for histogram, 0.99 for HOG and 0.99 for all combined into one.\n",
    "2. **Normalizing the features : **As suggested in the lessons, when combining different features to train the classifier there is always a possiblity that one feature might turn out to be more dominant than the other. That is why after I extracted the features for the car and non-car images, I am using **StandardScalar** to normalize my feature set.\n",
    "3. **Train/Test splitting of data : **\"I then created a sample of only 500 images from the list above and then divided that into training the testing set. I have kept the testing test as 20% of the total data.\n",
    "3. **Create, train and test the classifier : **For classification I have created a SVM classifier and train and tested it out with different parameter yielding different accuracies. My final values for them in listed in the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters for extracting the features\n",
    "colorspace = 'HLS'\n",
    "orient = 9\n",
    "pix_per_cell = 16  # 8 gives out accuracy of 0.99 and 4 gives out accuracy of 1.0\n",
    "cell_per_block =4\n",
    "hog_channel = 'ALL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hog (432,)\n",
      "hog (432,)\n"
     ]
    }
   ],
   "source": [
    "# extracting features for cars and not-car images\n",
    "t=time.time()\n",
    "car_features = extract_features(all_cars[:1], color_space=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel)\n",
    "notcar_features = extract_features(all_non_cars[:1], color_space=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 Seconds to extract HOG features...\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "print(round(t2-t, 2), 'Seconds to extract HOG features...')\n",
    "print(len(car_features), len(notcar_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3600)\n"
     ]
    }
   ],
   "source": [
    "# Stacking all the feature vectors for cars and non-car images.\n",
    "# And then normalizing them all so that one feature doesnt become dominant in classification\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "X_scalar = StandardScaler().fit(X)\n",
    "scaled_X = X_scalar.transform(X)\n",
    "print(scaled_X.shape)\n",
    "\n",
    "# creating the labels vectors for cars and non-cars images\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spliting the sample data into training and testing set\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(X[400])\n",
    "plt.show()\n",
    "plt.plot(scaled_X[400])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating a linear SVM classifier to test the pipeline\n",
    "svc = LinearSVC()\n",
    "t1 = time.time() # start time\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time() # end time\n",
    "\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "\n",
    "# Checking the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "\n",
    "# Checking the prediction time for a single sample of 10 elements\n",
    "t=time.time()\n",
    "print('My SVC predicts: ', svc.predict(X_test))\n",
    "print('For these',len(X_test), 'labels: ', y_test)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', len(X_test),'labels with SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sliding Window Search ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.a : Describe how (and identify where in your code) you implemented a sliding window search. How did you decide what scales to search and how much to overlap windows?\n",
    "**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testing the sliding windows search\n",
    "test_image_1 = mpimg.imread('test_images\\\\test6.jpg')\n",
    "print(test_image_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spatial_size = (32, 32) # Spatial binning dimensions\n",
    "hist_bins = 32    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "y_start_stop = [400, 700] # Min and max in y to search in slide_window()\n",
    "\n",
    "draw_image = np.copy(test_image_1)\n",
    "windows = slide_window(test_image_1, y_start_stop=y_start_stop, xy_window=(96,96), xy_overlap=(0.5, 0.5))\n",
    "car_windows = search_windows(test_image_1, windows=windows, clf=svc, scaler=X_scalar, color_space=colorspace, spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "window_img = draw_boxes(test_image_1, car_windows, color=(0, 0, 255), thick=6)                    \n",
    "plt.imshow(window_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
